---
title: "ã€Swiftã€‘CoreML VisionKitã§æ‰‹æ›¸ãæ•°å­—ã‚’èªè­˜ã—ã¦ã¿ã‚‹"
emoji: "ğŸ™Œ"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: [Swift, swiftui, coreml, visionkit, AI]
published: false
---

# ã¯ã˜ã‚ã«
è¿‘å¹´ã€äººå·¥çŸ¥èƒ½(AI)æŠ€è¡“ã®é€²åŒ–ã¯ç›®è¦šã¾ã—ã„ã‚‚ã®ãŒã‚ã‚Šã¾ã™ã€‚Appleã¯Siriã‚’ã¯ã˜ã‚ã€å¾“æ¥ã‹ã‚‰æ©Ÿæ¢°å­¦ç¿’ã‚„AIã®åˆ†é‡ã«æ³¨åŠ›ã—ã¦ãã¾ã—ãŸã€‚ä»Šå›ã¯ã€ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ä¸Šã§å®Ÿè¡Œå¯èƒ½ãªCoreMLã¨VisionKitã‚’ç”¨ã„ã¦ã€iPhoneã§ã®ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ã®å®Ÿè£…ã‚’è©¦ã¿ãŸã„ã¨æ€ã„ã¾ã™ã€‚

## Core ML
iOS 13~ã®æ©Ÿèƒ½ã§ãƒ‡ãƒã‚¤ã‚¹ä¸Šã§å‹•ä½œã—ã¾ã™ã€‚
*"Core MLã¯ã€Appleã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’æ´»ç”¨ã—ã€ãƒ¡ãƒ¢ãƒªå æœ‰é‡ã¨é›»åŠ›æ¶ˆè²»é‡ã‚’æœ€å°é™ã«æŠ‘ãˆãªãŒã‚‰ã€å¹…åºƒã„ç¨®é¡ã®ãƒ¢ãƒ‡ãƒ«ãŒã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã§ãã‚‹ã‚ˆã†æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚"* [Appleå…¬å¼](https://developer.apple.com/jp/machine-learning/core-ml/)
ã¾ãŸã€PyTorchãªã©ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ä½œæˆã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã‚‚ä½¿ãˆã‚‹ã‚ˆã†ã§ã™ã€‚ä»¥å‰ã¯ãƒ‡ãƒã‚¤ã‚¹ã®æ€§èƒ½ä¸è¶³ã§ä¸€èˆ¬å‘ã‘ã«ã¯æº€è¶³ã—ãŸã‚‚ã®ã¯ä½œã‚Šã¥ã‚‰ã„å°è±¡ã§ã—ãŸãŒã€ãƒ‡ãƒã‚¤ã‚¹ã®æ€§èƒ½ã¯å¹´ã€…å‘ä¸Šã—ã¦ãŠã‚Šã€Core MLè‡ªä½“ã‚‚ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ä»Šå¾Œåˆ©ç”¨ã‚·ãƒ¼ãƒ³ã¯å¢—ãˆã¦ã„ãã¨äºˆæƒ³ã•ã‚Œã¾ã™ã€‚

ã¾ã è©³ã—ãä½¿ã£ã¦ã¯ãªã„ã®ã§ã™ãŒã€Xcodeä¸Šã§ãƒ¢ãƒ‡ãƒ«ã®æŒ™å‹•ã‚„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¤œè¨¼ã§ãã¾ã™ã€‚
![](/images/visionkit-coreml-number-recognition/image0.png)

## VisionKit
iOS 13~ã®æ©Ÿèƒ½ã§ã“ã¡ã‚‰ã‚‚ãƒ‡ãƒã‚¤ã‚¹ä¸Šã§å‹•ä½œã—ã¾ã™ã€‚Core MLã¨ã®é•ã„ã¯ç”»åƒèªè­˜ã«ç‰¹åŒ–ã—ãŸæ©Ÿèƒ½ã¨ã„ã†ã“ã¨ã§ã™ã€‚
*"Identify and extract information in the environment using the deviceâ€™s camera, or in images that your app displays.(ãƒ‡ãƒã‚¤ã‚¹ã®ã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨ã—ã¦ç’°å¢ƒå†…ã®æƒ…å ±ã€ã¾ãŸã¯ã‚¢ãƒ—ãƒªãŒè¡¨ç¤ºã™ã‚‹ç”»åƒå†…ã®æƒ…å ±ã‚’è­˜åˆ¥ã—ã¦æŠ½å‡ºã—ã¾ã™ã€‚)"* [Appleå…¬å¼](https://developer.apple.com/documentation/visionkit)

ã‚«ãƒ¡ãƒ©ä¸Šã®ãƒ†ã‚­ã‚¹ãƒˆã‚„ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ãªã©ã‚’ã»ã¼é…å»¶ãªãèªè­˜ã§ããŸã‚Šã—ã¾ã™ã€‚
çµæ§‹ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ã®ç•ªå·å…¥åŠ›çœç•¥ã¨ã‹ã®æ©Ÿèƒ½ã‚’æ—¢å­˜ã‚¢ãƒ—ãƒªã§ã‚‚ä½¿ã£ã¦ã„ãŸã‚Šã—ã¦ã„ã‚‹ã®ã§ã€ã“ã¡ã‚‰ã®ã»ã†ãŒãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã«æ¡ç”¨ã—ã¦ã„ã‚‹ã¨ã“ã‚ãŒå¤šã„å°è±¡ã§ã™ã€‚

WWDC2023ã§ã¯ã€ç”»åƒã®ãªã‹ã®äººç‰©ã‚„ç‰©ä½“ã‚’è‡ªå‹•çš„ã«åˆ‡ã‚Šå‡ºã—ãŸã‚Šã™ã‚‹ã“ã¨ãŒå¤§ããªè©±é¡Œã¨ãªã‚Šã¾ã—ãŸã€‚

https://developer.apple.com/videos/play/wwdc2023/10048/

ä»Šå¾Œã¯VisionOSã¨ã®çµ„ã¿åˆã‚ã›ãªã©ã€è¦–è¦šåˆ†é‡ã¯AIã§ã‚‚Hotãªé ˜åŸŸã«ãªã‚‹å¯èƒ½æ€§ãŒå¤§ã„ã«ã‚ã‚Šã¾ã™ã€‚

# å®Ÿè£…ã®ä¸­èº«
ãã‚Œã§ã¯ã€ä»Šå›ã®å®Ÿè£…ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ã„ãã¾ã™ã€‚

### ä¸»ãªä½¿ç”¨æŠ€è¡“
- Core ML
- VisionKit
- PencilKit

### å‹•ä½œç’°å¢ƒ
- Xcode 15.0
- iOS 17.0
- Swift 5.0

## Pencil Kit
ä»Šå›æ‰‹æ›¸ãå…¥åŠ›ã®ã¨ãã«å…±é€šã—ã¦ä½¿ç”¨ã—ãŸã®ãŒ`Pencil Kit`ã§ã™
ã“ã‚Œã«ã‚ˆã£ã¦ã€çŸ­ã„ã‚³ãƒ¼ãƒ‰ã§ç°¡å˜ã«æ‰‹æ›¸ãå…¥åŠ›ãŒå¯èƒ½ã¨ãªã‚Šã¾ã—ãŸã€‚

https://developer.apple.com/documentation/pencilkit

```swift
struct CanvasView: UIViewRepresentable {
    let canvas: PKCanvasView
    
    func makeUIView(context: Context) -> some UIView {
        canvas.backgroundColor = .white
        canvas.drawingPolicy = .anyInput
        let toolPicker = PKToolPicker()
        toolPicker.addObserver(canvas)
        toolPicker.setVisible(true, forFirstResponder: canvas)
        canvas.becomeFirstResponder()
        canvas.tool = PKInkingTool(.pen, color: .black, width: 30)
        return canvas
    }
    
    func updateUIView(_ uiView: UIViewType, context: Context) {}
    
    func reset() {
        canvas.drawing = PKDrawing()
    }
}
```

:::message
ã¡ãªã¿ã«ã“ã“ã§`canvas.tool = PKInkingTool(.pen, color: .black, width: 30)`ã¨ã—ã¦å¹…ã‚’å¤ªã‚ã«æŒ‡å®šã—ã¦ã‚‹ã‚“ã§ã™ãŒã€å½“åˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã‚„ã£ã¦ã„ã‚‹ã¨ï¼‘ã¨ã—ã‹èªè­˜ã•ã‚Œãªã‹ã£ãŸãŸã‚ã§ã™ã€‚ãŠãã‚‰ãç´°ã™ãã¦ã€ã†ã¾ãèªè­˜ãŒåæ˜ ã•ã‚Œãªã‹ã£ãŸã¨æ€ã‚ã‚Œã¾ã™ã€‚
:::

## Core ML
ä»Šå›ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ã€Appleå…¬å¼ãŒé…å¸ƒã—ã¦ã„ã‚‹[Core MLãƒ¢ãƒ‡ãƒ«ã®ãƒšãƒ¼ã‚¸](https://developer.apple.com/jp/machine-learning/models/#image)ã§ä½¿ã„ãŸã„ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
æ•°å­—ã‚’èªè­˜ã—ãŸã„ãŸã‚ã€MNISTï¼ˆç·šç”»è­˜åˆ¥ï¼‰ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã„ã¾ã™ã€‚

ã“ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸMNISTClassifier.modelã‚’ã‚¢ãƒ—ãƒªãƒ•ã‚©ãƒ«ãƒ€ã®ä¸­ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã™ã€‚

![](/images/visionkit-coreml-number-recognition/image1.png =300x)

ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã‚‹ã¨ã€â†“ã®ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã‚’è¦‹ã‚‹ã“ã¨ãŒå‡ºæ¥ã¾ã™ã€‚

![](/images/visionkit-coreml-number-recognition/image2.png)

Previewã§ã¯å®Ÿéš›ã«ç”»åƒã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ã€ç²¾åº¦ã‚’è¦‹ã‚‹ã“ã¨ãŒå‡ºæ¥ã¾ã™ã€‚
ï¼ˆã‚ã‚Œã€5:ä¿¡é ¼åº¦100%ã¨ãªã£ã¦ã„ã‚‹ãƒ»ãƒ»ãƒ»ãƒ»ï¼‰

![](/images/visionkit-coreml-number-recognition/image3.png)

### ç”»åƒèªè­˜éƒ¨åˆ†ã®å®Ÿè£…
ä»Šå›ã®ã‚±ãƒ¼ã‚¹ã§ã¯ã€
1. ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©
2. ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ
3. ä½¿ç”¨ã™ã‚‹ç”»åƒã®å–å¾—
4. ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Ÿè¡Œ
ã¨ã„ã†æµã‚Œã«ãªã‚Šã¾ã™ã€‚
Core MLã¨VisionKitã®é•ã„ã¨ã—ã¦ã¯VisionKitã®å ´åˆã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ã¨ã“ã‚ã«ã™ã§ã«æ¨™æº–ã§ç”¨æ„ã•ã‚ŒãŸç”»åƒèªè­˜ç”¨ç­‰ã®APIãŒã‚ã‚‹ã®ã§ã€ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

### 1.ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©
`VNCoreMLModel`ã®ã‚ã¨ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åã§ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã—ã¾ã™ã€‚

```swift
let model = try! VNCoreMLModel(for: MNISTClassifier.init(configuration: .init()).model)
```

### 2.ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ

```swift
let request = VNCoreMLRequest(model: model) { request, error in
            guard let results = request.results as? [VNClassificationObservation] else {return}
            recognizedNumber = results.first?.identifier ?? ""
        }
```

### 3.ä½¿ç”¨ã™ã‚‹ç”»åƒã®å–å¾—
Pencil Kitã®APIã«ã¯æç”»é ˜åŸŸã‹ã‚‰ç”»åƒã‚’å–å¾—ã§ãã‚‹ä¾¿åˆ©ãªAPIãŒã‚ã‚‹ã®ã§ã€ã“ã¡ã‚‰ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚

```swift
let inputImage = canvasView.canvas.drawing.image(from: canvasView.canvas.bounds, scale: 1)
```

### 4.ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Ÿè¡Œ
ã•ãã»ã©å–å¾—ã—ãŸç”»åƒã‚’cgImageã«å¤‰æ›ã—ãŸã‚‚ã®ã‚’ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã«ç™»éŒ²ã—ã¦ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```swift
    let handler = VNImageRequestHandler(cgImage: inputImage.cgImage!)
    do {
        try handler.perform([request])
    } catch {
        print(error.localizedDescription)
    }
```

ã“ã‚ŒãŒä¸€é€£ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ã§ã™ã€‚
é–¢æ•°ã¨ã—ã¦ã¾ã¨ã‚ã‚‹ã¨æ¬¡ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

```swift
    func recognize() {
        let model = try! VNCoreMLModel(for: MNISTClassifier.init(configuration: .init()).model)
        let request = VNCoreMLRequest(model: model) { request, error in
            guard let results = request.results as? [VNClassificationObservation] else {return}
            recognizedNumber = results.first?.identifier ?? ""
        }
        let inputImage = canvasView.canvas.drawing.image(from: canvasView.canvas.bounds, scale: 1)
        let handler = VNImageRequestHandler(cgImage: inputImage.cgImage!)
        do {
            try handler.perform([request])
        } catch {
            print(error.localizedDescription)
        }
    }
```
### å®Ÿè¡Œ

UIéƒ¨åˆ†ã‚’ç°¡å˜ã«ã¾ã¨ã‚ã¾ã™ã€‚

```swift
    @State private var recognizedNumber = ""
    let canvasView = CanvasView(canvas: PKCanvasView())

    var body: some View {
        VStack {
            Text(recognizedNumber)
            VStack {
                canvasView
                    .frame(width: 150, height: 150)
            }
            Button(action: {
                recognize()
            }, label: {
                Text("å›ç­”ã™ã‚‹")
            })
            Button(action: {
                canvasView.reset()
            }, label: {
                Text("Reset")
            })
        }
        .padding()
    }
```

ãã‚Œã§ã¯å®Ÿæ©Ÿã§å®Ÿè¡Œã—ã¾ã™ã€‚

:::message
å‹•ä½œç¢ºèªã¯å®Ÿæ©Ÿã§è¡Œã†å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
å½“åˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã§è¡ŒãŠã†ã¨ã—ã¾ã—ãŸãŒã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦ã€`usesCPUOnly = true`ã«ã™ã‚‹ã¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã‚‚å‹•ä½œã™ã‚‹ã¨ã‚ã‚Šã¾ã—ãŸãŒã€iOS 17.0ã‹ã‚‰ã¯deprecatedã¨ãªã£ã¦ã„ã¾ã™ã€‚ï¼ˆä»£æ›¿æ–¹æ³•ã¯ã—ã‚ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ï¼‰

https://developer.apple.com/documentation/vision/vnrequest/2923480-usescpuonly
:::

![](/images/visionkit-coreml-number-recognition/coreml_sample.gif)

ã†ãƒ¼ã‚“ã€æœ€åˆã¯è‰¯ã•ãã†ã ã£ãŸã‚“ã§ã™ãŒã€ç²¾åº¦ã¯ã¾ã ã¾ã ãªã‚ˆã†ã§ã™ã€‚
ã“ã‚Œä»¥å¤–ã«ã‚‚ï¼—ã‚’1ã¨èªè­˜ã—ãŸã‚Šã™ã‚‹ã“ã¨ãŒçµæ§‹å¤šã‹ã£ãŸã§ã™ã€‚ä»Šå›ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ä¸€æ¡ã®æ•°å­—ã‚’å­¦ç¿’ã•ã›ãŸã ã‘ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ãŸã‚ã€ç”»åƒå‡¦ç†ã®ã¨ã“ã‚ã§ã‚‚ã†ã²ã¨å·¥å¤«å¿…è¦ãªã®ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼ˆç”»åƒã‚µã‚¤ã‚ºã®æ­£è¦åŒ–ã‚„ãƒ”ã‚¯ã‚»ãƒ«å‡¦ç†ãªã©ï¼‰ã€‚

ãã‚Œã§ã¯æ¬¡ã®VisionKitã‚’åˆ©ç”¨ã—ãŸæ–¹æ³•ã‚’ã‚„ã£ã¦ã¿ã¾ã™ã€‚

## VisionKit
VisionKitã®å ´åˆã¯ã€`import Vision`ã¨æ›¸ãã ã‘ã§ä½¿ãˆã¾ã™ã€‚ä¾¿åˆ©ã§ã™ã­ã€‚

### ç”»åƒèªè­˜éƒ¨åˆ†ã®å®Ÿè£…
Core MLã®ã¨ã“ã‚ã§ã‚‚è¨€åŠã—ãŸã‚ˆã†ã«ã€VisionKitã¯ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ã™ã‚‹å¿…è¦ã¯ãªãã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ã¨ã“ã‚ã§ã€ã„ã‚ã„ã‚ãªç¨®é¡ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ç”¨é€”ã«å¿œã˜ã¦ä½¿ã†ã ã‘ã§å¤§ä¸ˆå¤«ã§ã™ã€‚

é–¢æ•°ã¨ã—ã¦ã¾ã¨ã‚ãŸã‚‚ã®

```swift
    func recognize() {
        let request = VNRecognizeTextRequest { request, error in
            if let results = request.results as? [VNRecognizedTextObservation] {
                let recognizedStrings = results.compactMap{ observation in
                    let str = observation.topCandidates(1).compactMap { text in
                        text.string
                    }
                    return str
                }.joined()
                inputText = recognizedStrings.joined()
            }
        }
        request.recognitionLevel = .fast
        let inputImage = canvasView.canvas.drawing.image(from: canvasView.canvas.bounds, scale: 1)
        let imageRequestHandler = VNImageRequestHandler(cgImage: inputImage.cgImage!)
        DispatchQueue.main.async {
            do {
                try imageRequestHandler.perform([request])
            } catch {
                print(error)
            }
        }
    }

```

### å®Ÿè¡Œ

UIéƒ¨åˆ†ã¯æ¬¡ã®ã‚ˆã†ã«ãªã£ã¦ã¾ã™ã€‚

```swift
@State var recognizedText = ""

    var body: some View {
        VStack {
            Text(recognizedText)
                .font(.system(size: 30))
            canvasView
                .frame(height: 200)
            Button(action: {
                recognize()
            }, label: {
                Text("Recognize")
            })
            Button(action: {
                canvasView.reset()
            }, label: {
                Text("Reset")
            })
        }
        .background(Color.green)
        .padding()
    }
```

ãã‚Œã§ã¯å®Ÿè¡Œã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚â€»Previewã§ã‚‚ç¢ºèªã§ãã¾ã™ã€‚

å¤šåˆ†ä½•ã‚‚èªè­˜ã•ã‚Œãªã„çµæœã¨ãªã£ãŸã¨æ€ã„ã¾ã™ã€‚
ã©ã†ã‚„ã‚‰ç”»åƒã«ç™½èƒŒæ™¯ã‚’åŠ ãˆãªã„ã¨é§„ç›®ã‚‰ã—ã„ã§ã™ã€‚

https://note.com/sab_swiftlin/n/n9f1df57281b4

ã“ã¡ã‚‰ã®è¨˜äº‹ã«ã‚ã‚‹ã‚ˆã†ãªã‚„ã‚Šæ–¹ã§ã¯ãªãã€ImageRenderã‚’ä½¿ã£ã¦ã€Viewã‚’ãã®ã¾ã¾ç”»åƒã¨ã—ã¦å–ã‚Šè¾¼ã‚€æ–¹æ³•ã‚’ä½¿ã£ã¦ã‚„ã£ã¦ã¿ã¾ã—ãŸã€‚

```swift
    private var outputView: some View {
        ZStack {
            if let inputImage = inputImage {
                Image(uiImage: inputImage)
            }
        }.background(.white)
    }

    @MainActor func recognize() {
        // çœç•¥
        ãƒ»
        ãƒ»
        let canvasImage = canvasView.canvas.drawing.image(from: canvasView.canvas.bounds, scale: 1)
        inputImage = canvasImage
        let requestImage = ImageRenderer(content: outputView)
        let imageRequestHandler = VNImageRequestHandler(cgImage: requestImage.cgImage!)
        // çœç•¥
    }

```

ãã‚Œã§ã¯å®Ÿè¡Œã—ã¦ã¿ã¾ã™ã€‚

![](/images/visionkit-coreml-number-recognition/visionkit_sample.gif)

ãã“ã¾ã§ç²¾åº¦ã¯æ‚ªããªã„ã¾ã§ã‚‚ã€æ•°å­—ä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¸èªè­˜ã•ã‚Œã¦ã—ã¾ã£ãŸã‚Šã—ã¾ã™ã­ã€‚æ•°å­—ã®ï¼‘ã«ã¤ã„ã¦ã‚‚ã€lã‚„Iã¨ä¼¼ã¦ã„ã‚‹ãŸã‚ã€ä¸€æ–‡å­—ãªã©ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒãªã„çŠ¶æ…‹ã§ã¯ã€æ­£ã—ãèªè­˜ã™ã‚‹ã®ã¯é›£ã—ãã†ã§ã™ã€‚
ã“ã“ã‚‰ã¸ã‚“ã¯èªè­˜å€™è£œã‹ã‚‰ä¸€ç•ªä¿¡é ¼åº¦ã®é«˜ã„æ•°å­—ã®ã¿å–ã‚Šå‡ºã™ã€ã¨ã„ã†æ–¹æ³•ã‚’ã¨ã‚‹ãªã©ã™ã‚Œã°ã‚‚ã£ã¨ã†ã¾ãã„ããã†ã§ã™ã€‚

## ã¾ã¨ã‚
å½“åˆã®ç›®çš„ã ã£ãŸæ‰‹æ›¸ãã‹ã‚‰ã®æ•°å­—ã®èªè­˜ã¨ã„ã†ã®ã¯ã€ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ç²¾åº¦ã¨ã—ã¦ã‚ã¾ã‚Šå®Ÿç”¨ã«è€ãˆã‚Œã‚‹ãƒ¬ãƒ™ãƒ«ã§ã¯ãªã„ãªã€ã¨æ€ã„ã¾ã—ãŸã€‚ã—ã‹ã—ã€AIã‚„æ©Ÿæ¢°å­¦ç¿’ã®åˆ†é‡ã®æˆé•·é€Ÿåº¦ã¯å‡„ã¾ã˜ã„ã®ã§ã€ãŠãã‚‰ããã†é ããªã„æœªæ¥ã«ã¯ã“ã“ã‚‰ã¸ã‚“ãŒè§£æ±ºã•ã‚Œã¦ã„ã‚‹ã¨æ€ã„ã¾ã™ã€‚
ãŠèª­ã¿ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚

## å‚è€ƒã«ã•ã›ã¦ã„ãŸã ã„ãŸè¨˜äº‹ã¨ã‹
https://developer.apple.com/jp/machine-learning/core-ml/

https://developer.apple.com/documentation/visionkit

https://note.com/sab_swiftlin/n/n9f1df57281b4