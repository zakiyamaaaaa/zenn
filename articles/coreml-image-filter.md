---
title: "ã€SwiftUIã€‘CoreML, Visionã‚’ä½¿ã£ã¦ç”»åƒåŠ å·¥ã‚¢ãƒ—ãƒªã‚’ä½œã‚‹"
emoji: "ğŸ§‘â€ğŸ¨"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: [SwiftUI, Swift, CoreML, Vision, AI, æ©Ÿæ¢°å­¦ç¿’]
published: true
---

# ã¯ã˜ã‚ã«
iOSã®æ©Ÿæ¢°å­¦ç¿’ã§ã‚ã‚‹`CoreML`ã‚’ä½¿ã£ã¦ç”»åƒã®åŠ å·¥ã‚’ã‚„ã£ã¦ã¿ãŸã„ã¨æ€ã„ã¾ã™ã€‚
`CoreML`ã®æ¦‚è¦ã«ã¤ã„ã¦ã€[Appleå…¬å¼ãƒšãƒ¼ã‚¸](https://developer.apple.com/jp/documentation/coreml/)ã‹ã‚‰å¼•ç”¨ã—ã¾ã™ã€‚

> Core MLã‚’ä½¿ã£ã¦ã€æ©Ÿæ¢°è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒ—ãƒªã«çµ±åˆã—ã¾ã™ã€‚Core MLã¯ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’çµ±ä¸€ã•ã‚ŒãŸæ–¹æ³•ã§æ‰±ãˆã¾ã™ã€‚ã‚¢ãƒ—ãƒªã¯ã€Core ML APIã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€äºˆæ¸¬ã®ä½œæˆã€ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„å¾®èª¿æ•´ã‚’ã™ã¹ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ‡ãƒã‚¤ã‚¹ä¸Šã§è¡Œã„ã¾ã™ã€‚

æœ€è¿‘ã§ã¯ã€ãƒ‡ãƒã‚¤ã‚¹ä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã§ããŸã‚Šã€ãã®ã‚¹ãƒ”ãƒ¼ãƒ‰ãŒå‘ä¸Šã—ãŸã‚Šã—ã¦ãŠã‚Šã€ç”»åƒç”Ÿæˆã¨ã‹ã‚‚å¯èƒ½ã«ãªã£ã¦ã„ã¾ã™ã€‚
ã—ã‹ã—ã€ä»Šå›ã¯æ‰‹è»½ã«ç”»åƒåŠ å·¥ã‚’è¡Œã†ãŸã‚ã«ã€ã™ã§ã«ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã‚¢ãƒ—ãƒªã‚’å®Ÿè£…ã—ã¦ã„ãã¾ã™ã€‚

ã¾ãŸã€ã“ã“ã§ã¯`Visionãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯`ï¼ˆå¾Œè¿°ã§ã¯Visionï¼‰ã‚’ä½¿ã£ã¦ã„ã¾ã™ã€‚`Vision`ã¯ã€ç”»åƒèªè­˜ç³»ã®æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ç”»åƒã‚„å‹•ç”»ã«å¯¾å¿œã—ã¾ã™ã€‚[Appleå…¬å¼ãƒšãƒ¼ã‚¸](https://developer.apple.com/documentation/vision/)

`Vision`ã®ã»ã†ã‚‚OSã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã«ä¼´ã„ã€æ§˜ã€…ãªæ©Ÿèƒ½ãŒè¿½åŠ ãƒ»ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œã¦ãŠã‚Šã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®æ·±åº¦æ¸¬å®šã‚„ç”»åƒåˆ†é¡ãªã©ãŒå¯èƒ½ã¨ãªã‚Šã¾ã™ã€‚

å¯¾å¿œãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦ã§ã™ãŒã€`CoreML`,`Vision`ã¨ã‚‚ã«iOS 11.0~ãªã®ã§ã€2025å¹´ç¾åœ¨ã§ã¯ã€ã»ã¼ã™ã¹ã¦ã®ã‚¢ãƒ—ãƒªã§å¯¾å¿œå¯èƒ½ã¨ãªã‚Šã¾ã™ã€‚

æ¬¡ç« ã‹ã‚‰å®Ÿè£…ã«ã¤ã„ã¦ã®å…·ä½“çš„ãªèª¬æ˜ã«å…¥ã‚Šã¾ã™ãŒã€ãã®å‰ã«å®Ÿè¡Œç’°å¢ƒã‚’å‚è€ƒçš„ã«ç¤ºã—ã¾ã™ã€‚XcodeãŒå‹•ãç’°å¢ƒã§ã‚ã‚Œã°ã€ã ã„ãŸã„å¤§ä¸ˆå¤«ã ã¨æ€ã„ã¾ã™ã€‚

* macOS: Sequoia 15.2
* Xcode: 16.2
* Swift: 5

## å®Ÿè£…
### æµã‚Œ
ã¾ãšã€ä»Šå›ã¤ãã‚‹ã‚¢ãƒ—ãƒªã®æµã‚Œã‚’èª¬æ˜ã—ã¾ã™ã€‚
1. ãƒ­ãƒ¼ã‚«ãƒ«ã®ç”»åƒãŒå…¥ã£ã¦ã‚‹çŠ¶æ…‹ã§ã‚¢ãƒ—ãƒªãŒèµ·å‹•
2. ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€å¯¾è±¡ã®ç”»åƒãŒãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦åŠ å·¥å‡¦ç†
3. åŠ å·¥ãŒçµ‚ã‚ã£ãŸã‚‰ã€åŠ å·¥å¾Œã®ç”»åƒã‚’è¡¨ç¤º

ã¨ã„ã†ç°¡å˜ãªæµã‚Œã«ãªã‚Šã¾ã™ã€‚
ãã‚Œã§ã¯æ—©é€Ÿä½œã‚Šå§‹ã‚ãŸã„ã¨ã“ã‚ã§ã™ãŒã€ã¾ãšåˆã‚ã«ä»Šå›ä½¿ç”¨ã™ã‚‹CoreMLã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ãã¾ã™ã€‚

### Modelã‚¤ãƒ³ãƒãƒ¼ãƒˆ
ä»Šå›ã¯ã“ã¡ã‚‰ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰CoreMLãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ãã¾ã™ã€‚ãªãŠãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯è‡ªå·±åˆ¤æ–­ã¨ã—ã¾ã™ã€‚

https://github.com/john-rocky/CoreML-Models

ä»Šå›è¡Œã†ã‚¿ã‚¹ã‚¯ã¯Image2Imageï¼ˆç”»åƒã‹ã‚‰ç”»åƒï¼‰ã¨ãªã‚‹ã®ã§ã€Image2Imageã®ä¸­ã‹ã‚‰é©å½“ã«é¸ã‚“ã§ã¿ã¦ãã ã•ã„ã€‚
ä¸€å¿œè‡ªåˆ†ãŒå‹•ã‹ã—ãŸã®ã¯ã€[animeGANv2_paprika](https://github.com/john-rocky/CoreML-Models?tab=readme-ov-file#animeGANv2_paprika)ã¨ãªã‚Šã¾ã™ã€‚
æŒ‡å®šã®Google Driveã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ããŸ`.mlmodel`ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•ã—ã¾ã™ã€‚

![](/images/coreml-image-filter/image1.png)

ã“ã‚Œã ã‘ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¯çµ‚ã‚ã‚Šã§ã™ã€‚
ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ã€Xcodeã‹ã‚‰è©²å½“ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã‚‹ã¨ã“ã‚“ãªæ„Ÿã˜ã§ã€ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°ãŒè¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã“ã‚‰ã¸ã‚“ã®æ©Ÿèƒ½ã¨ã‹ã¯ã€ã“ã®è¨˜äº‹ã§ã¯æ‰±ã„ã¾ã›ã‚“ã€‚

![](/images/coreml-image-filter/image2.png)

### Visionã§ãƒ¢ãƒ‡ãƒ«ã‚’æ‰±ã†
ãã‚Œã§ã¯ã€å…ˆã»ã©ã„ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã„ãã¾ã™ã€‚
ãƒ¢ãƒ‡ãƒ«ã®å‚ç…§ã¯ã“ã‚“ãªæ„Ÿã˜ã§ã™ã€‚

```swift
let model = try? VNCoreMLModel(for: animeganPaprika(configuration: .init()).model)
```

ã“ã“ã®`animeganPaprika`ãŒãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«åãªã®ã§ã™ãŒã€Xcodeã®ã»ã†ã§è‡ªå‹•çš„ã«èªè­˜ã—ã¦ã€è£œå®ŒãŒåŠ¹ã„ã¦å…¥åŠ›ã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚

ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã‹ã‚’äºˆæ¸¬ã—ã¦ã„ãã¾ã™ã€‚

```swift
let request = VNCoreMLRequest(model: model) { request, error in ...
```

è¿”å´å€¤ã¨ã—ã¦ã¯ã€ç”»åƒåˆ†é¡ã®å ´åˆã¯ã€`VNClassificationObservation`ã€‚ä»Šå›ã®image2imageã®å ´åˆã¯ã€`VNPixelBufferObservations`ã€‚ãã‚Œä»¥å¤–ã¯ã®å ´åˆã¯`VNRecognizedObjectObservation`ã¾ãŸã¯`VNCoreMLFeatureValueObservation`ã¨ãªã‚Šã¾ã™ã€‚

ç”»åƒã‚’åŠ å·¥ã™ã‚‹å‡¦ç†ã®ã‚³ãƒ¼ãƒ‰ã¨ã—ã¦ã¯ã€æ¬¡ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
`isProcessing`ã¯åŠ å·¥ä¸­ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°ã§ã™ã€‚

```swift
private func processImage(_ image: UIImage) {
        isProcessing = true
        guard let model = try? VNCoreMLModel(for: animeganPaprika(configuration: .init()).model),
              let ciImage = CIImage(image: image) else {
            print("Failed to load model or image")
            isProcessing = false
            return
        }

        let request = VNCoreMLRequest(model: model) { request, error in
            DispatchQueue.main.async {
                if let results = request.results as? [VNPixelBufferObservation],
                   let firstResult = results.first {
                    self.processedImage = UIImage(pixelBuffer: firstResult.pixelBuffer, targetSize: image.size)
                } else {
                    print("No results found: \(String(describing: error))")
                }
                self.isProcessing = false
            }
        }

        let handler = VNImageRequestHandler(ciImage: ciImage, options: [:])
        DispatchQueue.global(qos: .userInitiated).async {
            do {
                try handler.perform([request])
            } catch {
                print("Error performing request: \(error)")
                self.isProcessing = false
            }
        }
    }
```

### ã‚³ãƒ¼ãƒ‰
å…¨ä½“ã®ã‚³ãƒ¼ãƒ‰ã¯æ¬¡ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚`originalImage`ã®å‚ç…§å…ˆã¯é©å®œå¤‰æ›´ã—ã¦ãã ã•ã„ã€‚

```swift
import SwiftUI
import CoreML
import Vision

struct ContentView: View {
    @State private var originalImage = UIImage(resource: .sample)
    @State private var processedImage: UIImage?
    @State private var isProcessing: Bool = false

    var body: some View {
        VStack {
            
                Image(uiImage: originalImage)
                    .resizable()
                    .scaledToFit()
                    .frame(height: 200)
                    .padding()

            if let processedImage = processedImage {
                Image(uiImage: processedImage)
                    .resizable()
                    .scaledToFit()
                    .frame(height: 200)
                    .padding()
            } else if isProcessing {
                ProgressView("Processing Image...")
            }

            Button("Process Image") {
                    processImage(originalImage)
            }
            .padding()
        }
    }

    private func processImage(_ image: UIImage) {
        isProcessing = true
        guard let model = try? VNCoreMLModel(for: animeganPaprika(configuration: .init()).model),
              let ciImage = CIImage(image: image) else {
            print("Failed to load model or image")
            isProcessing = false
            return
        }

        let request = VNCoreMLRequest(model: model) { request, error in
            DispatchQueue.main.async {
                if let results = request.results as? [VNPixelBufferObservation],
                   let firstResult = results.first {
                    self.processedImage = UIImage(pixelBuffer: firstResult.pixelBuffer, targetSize: image.size)
                } else {
                    print("No results found: \(String(describing: error))")
                }
                self.isProcessing = false
            }
        }

        let handler = VNImageRequestHandler(ciImage: ciImage, options: [:])
        DispatchQueue.global(qos: .userInitiated).async {
            do {
                try handler.perform([request])
            } catch {
                print("Error performing request: \(error)")
                self.isProcessing = false
            }
        }
    }
}

extension UIImage {
    convenience init?(pixelBuffer: CVPixelBuffer, targetSize: CGSize) {
        let ciImage = CIImage(cvPixelBuffer: pixelBuffer)
        let context = CIContext()
        guard let cgImage = context.createCGImage(ciImage, from: ciImage.extent) else {
            return nil
        }
        let renderer = UIGraphicsImageRenderer(size: targetSize)
        let resizedImage = renderer.image { _ in
            UIImage(cgImage: cgImage).draw(in: CGRect(origin: .zero, size: targetSize))
        }
        self.init(cgImage: resizedImage.cgImage!)
    }
}

#Preview {
    ContentView()
}
```

å®Ÿè¡Œã™ã‚‹ã¨ã€æ¬¡ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

![](/images/coreml-image-filter/movie1.gif)

# ãŠã‚ã‚Šã«
ãŸã¶ã‚“ã€ã‚ã¾ã‚Šæ¥­å‹™çš„ã«ä½¿ã‚ã‚Œã‚‹ã“ã¨ãŒãªã„ç”»åƒåŠ å·¥ãªã‚“ã§ã™ãŒã€CoreMLã‚’çŸ¥ã‚‹ãŸã‚ã«ã¯è‰¯ã„æ•™æã‹ãªã€ã¨æ€ã„ã¾ã—ãŸã€‚ãã—ã¦ã€å®Ÿéš›ã«å‹•ã‹ã—ã¦ã¿ã¦ãã®å‡¦ç†é€Ÿåº¦ãŒã»ã¼ä¸€ç¬ã ã£ãŸã®ã«é©šãã¾ã—ãŸã€‚ç”ŸæˆAIãŒæœ€è¿‘ã¯æµè¡Œã‚Šã§ã™ãŒã€ç”ŸæˆAIã§ã¯ãªã„æ©Ÿæ¢°å­¦ç¿’ç³»æŠ€è¡“ã‚‚é¢ç™½ã„ã¨æ€ã„ã¾ã™ã€‚
ãŸã ã€ä¸€ã¤èª²é¡Œã¨ã—ã¦ã¯ã€ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹åŠ å·¥ã®å¼·åº¦ã‚’ã‚¢ãƒ—ãƒªå´ã§èª¿æ•´ã™ã‚‹æ–¹æ³•ãŒè¦‹ã¤ã‘ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚AIã«èã„ãŸã¨ã“ã‚ã€å…ƒç”»åƒã¨ãƒã‚¹ã‚¯ã—ã¦è¡Œã†æ–¹æ³•ã‚’æç¤ºã•ã‚Œã¦ã‚„ã£ã¦ã¿ãŸã®ã§ã™ãŒã€ã†ã¾ãã§ããšã€‚ã“ã“ã‚‰ã¸ã‚“ã‚’æ¬¡ã®èª²é¡Œã¨ã—ã¦æŒ‘æˆ¦ã—ã¦ã¿ã¾ã™ã€‚
ã”è¦§ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚

https://x.com/yamazaking0

# å‚è€ƒã«ã—ãŸè¨˜äº‹
https://developer.apple.com/jp/documentation/coreml/

https://developer.apple.com/documentation/vision/

https://github.com/john-rocky/CoreML-Models



